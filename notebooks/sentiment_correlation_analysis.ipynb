{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Correlation between News and Stock Movement\n",
    "\n",
    "## Overview\n",
    "This notebook analyzes the relationship between news sentiment and stock price movements. We'll:\n",
    "1. Align news and stock price data\n",
    "2. Perform sentiment analysis on news headlines\n",
    "3. Calculate stock returns\n",
    "4. Analyze correlations between sentiment and price movements\n",
    "\n",
    "## Main Objectives\n",
    "1. Understand how to align time series data\n",
    "2. Perform sentiment analysis using NLP\n",
    "3. Calculate and interpret correlations\n",
    "4. Visualize relationships between sentiment and stock movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.0.3\n",
      "numpy version: 1.24.4\n",
      "nltk version: 3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/dinki/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/dinki/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Print library versions for reproducibility\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"nltk version: {nltk.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Exploration\n",
    "\n",
    "We'll load both datasets:\n",
    "1. News data (raw_analyst_ratings.csv)\n",
    "2. Stock price data (from yfinance_data directory)\n",
    "\n",
    "Let's examine both datasets to understand their structure and ensure proper alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Data Information:\n",
      "--------------------------------------------------\n",
      "Number of news articles: 1407328\n",
      "Date range: 2009-02-14 00:00:00 to 2020-06-11 17:12:35-04:00\n",
      "\n",
      "Columns in news data:\n",
      "['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock']\n",
      "\n",
      "Stock Data Information:\n",
      "--------------------------------------------------\n",
      "Number of trading days: 6421\n",
      "Date range: 1999-01-22 to 2024-07-30\n",
      "\n",
      "Columns in stock data:\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "\n",
      "Sample News Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \n",
       "0  2020-06-05 10:30:54-04:00     A  \n",
       "1  2020-06-03 10:45:20-04:00     A  \n",
       "2  2020-05-26 04:30:07-04:00     A  \n",
       "3  2020-05-22 12:45:06-04:00     A  \n",
       "4  2020-05-22 11:38:59-04:00     A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Stock Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-01-22</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.038802</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>2714688000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-25</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>510480000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-26</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>0.041797</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>343200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-27</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.038218</td>\n",
       "      <td>244368000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-28</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.041536</td>\n",
       "      <td>0.038098</td>\n",
       "      <td>227520000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close      Volume  \\\n",
       "0  1999-01-22  0.043750  0.048828  0.038802  0.041016   0.037621  2714688000   \n",
       "1  1999-01-25  0.044271  0.045833  0.041016  0.045313   0.041562   510480000   \n",
       "2  1999-01-26  0.045833  0.046745  0.041146  0.041797   0.038337   343200000   \n",
       "3  1999-01-27  0.041927  0.042969  0.039583  0.041667   0.038218   244368000   \n",
       "4  1999-01-28  0.041667  0.041927  0.041276  0.041536   0.038098   227520000   \n",
       "\n",
       "   Dividends  Stock Splits  \n",
       "0        0.0           0.0  \n",
       "1        0.0           0.0  \n",
       "2        0.0           0.0  \n",
       "3        0.0           0.0  \n",
       "4        0.0           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load news data\n",
    "news_data = pd.read_csv('../data/raw/raw_analyst_ratings.csv')\n",
    "\n",
    "# Load stock data (using NVDA as example)\n",
    "stock_data = pd.read_csv('../data/raw/yfinance_data/NVDA_historical_data.csv')\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"News Data Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Number of news articles: {len(news_data)}\")\n",
    "print(f\"Date range: {news_data['date'].min()} to {news_data['date'].max()}\")\n",
    "print(\"\\nColumns in news data:\")\n",
    "print(news_data.columns.tolist())\n",
    "\n",
    "print(\"\\nStock Data Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Number of trading days: {len(stock_data)}\")\n",
    "print(f\"Date range: {stock_data['Date'].min()} to {stock_data['Date'].max()}\")\n",
    "print(\"\\nColumns in stock data:\")\n",
    "print(stock_data.columns.tolist())\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample News Data:\")\n",
    "display(news_data.head())\n",
    "\n",
    "print(\"\\nSample Stock Data:\")\n",
    "display(stock_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Date Alignment\n",
    "\n",
    "Before we can analyze the correlation between news sentiment and stock movements, we need to:\n",
    "1. Convert dates to datetime format\n",
    "2. Align news and stock data by date\n",
    "3. Handle any missing values\n",
    "4. Ensure proper timezone alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and examining the data...\n",
      "\n",
      "News Data Information:\n",
      "--------------------------------------------------\n",
      "Columns in news data:\n",
      "['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock']\n",
      "\n",
      "First few rows of news data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \n",
       "0  2020-06-05 10:30:54-04:00     A  \n",
       "1  2020-06-03 10:45:20-04:00     A  \n",
       "2  2020-05-26 04:30:07-04:00     A  \n",
       "3  2020-05-22 12:45:06-04:00     A  \n",
       "4  2020-05-22 11:38:59-04:00     A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Data Information:\n",
      "--------------------------------------------------\n",
      "Columns in stock data:\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "\n",
      "First few rows of stock data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-01-22</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.038802</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>2714688000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-25</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>510480000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-26</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>0.041797</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>343200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-27</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.038218</td>\n",
       "      <td>244368000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-28</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.041536</td>\n",
       "      <td>0.038098</td>\n",
       "      <td>227520000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close      Volume  \\\n",
       "0  1999-01-22  0.043750  0.048828  0.038802  0.041016   0.037621  2714688000   \n",
       "1  1999-01-25  0.044271  0.045833  0.041016  0.045313   0.041562   510480000   \n",
       "2  1999-01-26  0.045833  0.046745  0.041146  0.041797   0.038337   343200000   \n",
       "3  1999-01-27  0.041927  0.042969  0.039583  0.041667   0.038218   244368000   \n",
       "4  1999-01-28  0.041667  0.041927  0.041276  0.041536   0.038098   227520000   \n",
       "\n",
       "   Dividends  Stock Splits  \n",
       "0        0.0           0.0  \n",
       "1        0.0           0.0  \n",
       "2        0.0           0.0  \n",
       "3        0.0           0.0  \n",
       "4        0.0           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting dates...\n",
      "Date column in news data: ['date']\n",
      "Date column in stock data: ['Date']\n",
      "\n",
      "Date Ranges:\n",
      "News data: 2011-04-27 21:01:48-04:00 to 2020-06-11 17:12:35-04:00\n",
      "Stock data: 1999-01-22 00:00:00 to 2024-07-30 00:00:00\n",
      "\n",
      "Missing values in news data:\n",
      "Unnamed: 0    0\n",
      "headline      0\n",
      "url           0\n",
      "publisher     0\n",
      "stock         0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in stock data:\n",
      "Open            0\n",
      "High            0\n",
      "Low             0\n",
      "Close           0\n",
      "Adj Close       0\n",
      "Volume          0\n",
      "Dividends       0\n",
      "Stock Splits    0\n",
      "Daily_Return    1\n",
      "dtype: int64\n",
      "\n",
      "Aligned Data Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News_Count</th>\n",
       "      <th>Stock_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-01</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            News_Count  Stock_Return\n",
       "2011-04-27         1.0      0.000000\n",
       "2011-04-28         2.0      0.010881\n",
       "2011-04-29         2.0      0.025115\n",
       "2011-04-30         1.0           NaN\n",
       "2011-05-01         1.0           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let's examine the data structure\n",
    "print(\"Loading and examining the data...\")\n",
    "\n",
    "# Load news data\n",
    "news_data = pd.read_csv('../data/raw/raw_analyst_ratings.csv')\n",
    "\n",
    "# Load stock data\n",
    "stock_data = pd.read_csv('../data/raw/yfinance_data/NVDA_historical_data.csv')\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\nNews Data Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Columns in news data:\")\n",
    "print(news_data.columns.tolist())\n",
    "print(\"\\nFirst few rows of news data:\")\n",
    "display(news_data.head())\n",
    "\n",
    "print(\"\\nStock Data Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Columns in stock data:\")\n",
    "print(stock_data.columns.tolist())\n",
    "print(\"\\nFirst few rows of stock data:\")\n",
    "display(stock_data.head())\n",
    "\n",
    "# Now let's handle the date conversion\n",
    "try:\n",
    "    # Convert dates to datetime\n",
    "    print(\"\\nConverting dates...\")\n",
    "    \n",
    "    # First, let's check the date column names\n",
    "    print(\"Date column in news data:\", [col for col in news_data.columns if 'date' in col.lower()])\n",
    "    print(\"Date column in stock data:\", [col for col in stock_data.columns if 'date' in col.lower()])\n",
    "    \n",
    "    # Convert dates (adjust column names based on actual data)\n",
    "    date_col_news = [col for col in news_data.columns if 'date' in col.lower()][0]\n",
    "    date_col_stock = [col for col in stock_data.columns if 'date' in col.lower()][0]\n",
    "    \n",
    "    news_data[date_col_news] = pd.to_datetime(news_data[date_col_news], errors='coerce')\n",
    "    stock_data[date_col_stock] = pd.to_datetime(stock_data[date_col_stock], errors='coerce')\n",
    "    \n",
    "    # Set dates as index\n",
    "    news_data.set_index(date_col_news, inplace=True)\n",
    "    stock_data.set_index(date_col_stock, inplace=True)\n",
    "    \n",
    "    # Sort by date\n",
    "    news_data.sort_index(inplace=True)\n",
    "    stock_data.sort_index(inplace=True)\n",
    "    \n",
    "    # Calculate daily stock returns\n",
    "    stock_data['Daily_Return'] = stock_data['Close'].pct_change()\n",
    "    \n",
    "    # Display date ranges and data points\n",
    "    print(\"\\nDate Ranges:\")\n",
    "    print(f\"News data: {news_data.index.min()} to {news_data.index.max()}\")\n",
    "    print(f\"Stock data: {stock_data.index.min()} to {stock_data.index.max()}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values in news data:\")\n",
    "    print(news_data.isnull().sum())\n",
    "    print(\"\\nMissing values in stock data:\")\n",
    "    print(stock_data.isnull().sum())\n",
    "    \n",
    "    # Display aligned data\n",
    "    print(\"\\nAligned Data Sample:\")\n",
    "    display(pd.DataFrame({\n",
    "        'News_Count': news_data.groupby(news_data.index.date).size(),\n",
    "        'Stock_Return': stock_data['Daily_Return']\n",
    "    }).head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError occurred: {str(e)}\")\n",
    "    print(\"\\nLet's examine the data more closely:\")\n",
    "    print(\"\\nNews data info:\")\n",
    "    print(news_data.info())\n",
    "    print(\"\\nStock data info:\")\n",
    "    print(stock_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Setup\n",
    "\n",
    "Before we begin analyzing sentiment, we need to:\n",
    "1. Initialize our sentiment analyzers (VADER and TextBlob)\n",
    "2. Define our sentiment analysis functions\n",
    "3. Apply sentiment analysis to our news headlines\n",
    "4. Calculate basic sentiment statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a smaller sample for testing\n",
    "sample_size = 10000\n",
    "news_data_sample = news_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment_vader(text):\n",
    "    if not isinstance(text, str):\n",
    "        return {'compound': 0, 'pos': 0, 'neg': 0, 'neu': 0}\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Process the sample\n",
    "chunk_size = 1000\n",
    "processed_data = []\n",
    "\n",
    "print(f\"Processing {sample_size} headlines...\")\n",
    "\n",
    "for start_idx in range(0, sample_size, chunk_size):\n",
    "    end_idx = min(start_idx + chunk_size, sample_size)\n",
    "    chunk = news_data_sample.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    # Apply sentiment analysis\n",
    "    chunk['vader_sentiment'] = chunk['headline'].apply(analyze_sentiment_vader)\n",
    "    chunk['vader_compound'] = chunk['vader_sentiment'].apply(lambda x: x['compound'])\n",
    "    chunk['vader_positive'] = chunk['vader_sentiment'].apply(lambda x: x['pos'])\n",
    "    chunk['vader_negative'] = chunk['vader_sentiment'].apply(lambda x: x['neg'])\n",
    "    chunk['vader_neutral'] = chunk['vader_sentiment'].apply(lambda x: x['neu'])\n",
    "    \n",
    "    processed_data.append(chunk)\n",
    "    \n",
    "    print(f\"Progress: {(end_idx/sample_size)*100:.1f}%\")\n",
    "\n",
    "# Combine all processed chunks\n",
    "news_data_processed = pd.concat(processed_data)\n",
    "\n",
    "# Save the processed data\n",
    "news_data_processed.to_csv('../data/processed/sentiment_analysis_sample.csv', index=True)\n",
    "\n",
    "print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Distribution Analysis\n",
    "\n",
    "Now that we have calculated sentiment scores, we'll:\n",
    "1. Visualize the distribution of sentiment scores\n",
    "2. Compare VADER and TextBlob sentiment distributions\n",
    "3. Identify any patterns or biases in the sentiment analysis\n",
    "4. Understand the overall sentiment landscape of our news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# VADER sentiment distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(news_data_processed['vader_compound'], bins=50, kde=True)\n",
    "plt.title('Distribution of VADER Sentiment Scores')\n",
    "plt.xlabel('Compound Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# VADER positive/negative distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(news_data_processed['vader_positive'], bins=50, kde=True, label='Positive', alpha=0.5)\n",
    "sns.histplot(news_data_processed['vader_negative'], bins=50, kde=True, label='Negative', alpha=0.5)\n",
    "plt.title('Distribution of Positive and Negative Scores')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(\"\\nSentiment Analysis Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Mean compound score: {news_data_processed['vader_compound'].mean():.3f}\")\n",
    "print(f\"Mean positive score: {news_data_processed['vader_positive'].mean():.3f}\")\n",
    "print(f\"Mean negative score: {news_data_processed['vader_negative'].mean():.3f}\")\n",
    "print(f\"Mean neutral score: {news_data_processed['vader_neutral'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Sentiment Trends Analysis\n",
    "\n",
    "In this section, we'll analyze how sentiment changes over time by:\n",
    "1. Calculating daily average sentiment scores\n",
    "2. Visualizing sentiment trends over time\n",
    "3. Identifying any patterns or seasonality in sentiment\n",
    "4. Comparing sentiment trends with stock price movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily average sentiment\n",
    "print(\"Calculating daily sentiment trends...\")\n",
    "\n",
    "# Group by date and calculate mean sentiment scores\n",
    "daily_sentiment = news_data.groupby(news_data.index.date).agg({\n",
    "    'vader_compound': 'mean',\n",
    "    'textblob_sentiment': 'mean'\n",
    "}).reset_index()\n",
    "daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "daily_sentiment.set_index('date', inplace=True)\n",
    "\n",
    "# Plot daily sentiment trends\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(daily_sentiment.index, daily_sentiment['vader_compound'], label='VADER Sentiment')\n",
    "plt.plot(daily_sentiment.index, daily_sentiment['textblob_sentiment'], label='TextBlob Sentiment')\n",
    "plt.title('Daily Average Sentiment Scores')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display trend statistics\n",
    "print(\"\\nDaily Sentiment Trend Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"VADER Sentiment:\")\n",
    "print(f\"Overall trend: {daily_sentiment['vader_compound'].mean():.3f}\")\n",
    "print(f\"Maximum daily average: {daily_sentiment['vader_compound'].max():.3f}\")\n",
    "print(f\"Minimum daily average: {daily_sentiment['vader_compound'].min():.3f}\")\n",
    "print(f\"Standard deviation: {daily_sentiment['vader_compound'].std():.3f}\")\n",
    "\n",
    "print(\"\\nTextBlob Sentiment:\")\n",
    "print(f\"Overall trend: {daily_sentiment['textblob_sentiment'].mean():.3f}\")\n",
    "print(f\"Maximum daily average: {daily_sentiment['textblob_sentiment'].max():.3f}\")\n",
    "print(f\"Minimum daily average: {daily_sentiment['textblob_sentiment'].min():.3f}\")\n",
    "print(f\"Standard deviation: {daily_sentiment['textblob_sentiment'].std():.3f}\")\n",
    "\n",
    "# Calculate rolling averages to identify trends\n",
    "daily_sentiment['vader_rolling'] = daily_sentiment['vader_compound'].rolling(window=7).mean()\n",
    "daily_sentiment['textblob_rolling'] = daily_sentiment['textblob_sentiment'].rolling(window=7).mean()\n",
    "\n",
    "# Plot rolling averages\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(daily_sentiment.index, daily_sentiment['vader_rolling'], label='VADER 7-day Rolling Average')\n",
    "plt.plot(daily_sentiment.index, daily_sentiment['textblob_rolling'], label='TextBlob 7-day Rolling Average')\n",
    "plt.title('7-day Rolling Average of Sentiment Scores')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis: Sentiment vs Stock Returns\n",
    "\n",
    "Now that we have our sentiment scores and stock returns, we'll analyze their relationship by:\n",
    "1. Calculating daily correlations\n",
    "2. Visualizing the relationships\n",
    "3. Testing statistical significance\n",
    "4. Analyzing lag effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily average sentiment scores\n",
    "print(\"Calculating daily sentiment averages...\")\n",
    "\n",
    "daily_sentiment = news_data.groupby(news_data.index.date).agg({\n",
    "    'vader_compound': 'mean',\n",
    "    'textblob_sentiment': 'mean'\n",
    "}).reset_index()\n",
    "daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "daily_sentiment.set_index('date', inplace=True)\n",
    "\n",
    "# Merge with stock returns\n",
    "merged_data = pd.merge(\n",
    "    daily_sentiment,\n",
    "    stock_data['Daily_Return'],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_vader = merged_data['vader_compound'].corr(merged_data['Daily_Return'])\n",
    "correlation_textblob = merged_data['textblob_sentiment'].corr(merged_data['Daily_Return'])\n",
    "\n",
    "print(\"\\nCorrelation Analysis Results:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"VADER Sentiment Correlation: {correlation_vader:.3f}\")\n",
    "print(f\"TextBlob Sentiment Correlation: {correlation_textblob:.3f}\")\n",
    "\n",
    "# Visualize the relationships\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# VADER sentiment vs returns\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(merged_data['vader_compound'], merged_data['Daily_Return'], alpha=0.5)\n",
    "plt.title('VADER Sentiment vs Stock Returns')\n",
    "plt.xlabel('VADER Sentiment Score')\n",
    "plt.ylabel('Daily Return')\n",
    "\n",
    "# TextBlob sentiment vs returns\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(merged_data['textblob_sentiment'], merged_data['Daily_Return'], alpha=0.5)\n",
    "plt.title('TextBlob Sentiment vs Stock Returns')\n",
    "plt.xlabel('TextBlob Sentiment Score')\n",
    "plt.ylabel('Daily Return')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagged Correlation Analysis\n",
    "\n",
    "We'll analyze if there's a delayed effect between news sentiment and stock returns by:\n",
    "1. Calculating correlations with different time lags\n",
    "2. Identifying optimal lag periods\n",
    "3. Visualizing lag effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lagged correlations\n",
    "print(\"Calculating lagged correlations...\")\n",
    "\n",
    "max_lag = 5  # Analyze up to 5 days of lag\n",
    "lagged_correlations = pd.DataFrame(index=range(max_lag + 1))\n",
    "\n",
    "for lag in range(max_lag + 1):\n",
    "    if lag == 0:\n",
    "        lagged_correlations.loc[lag, 'VADER'] = correlation_vader\n",
    "        lagged_correlations.loc[lag, 'TextBlob'] = correlation_textblob\n",
    "    else:\n",
    "        # Calculate lagged correlations\n",
    "        lagged_correlations.loc[lag, 'VADER'] = merged_data['vader_compound'].corr(merged_data['Daily_Return'].shift(-lag))\n",
    "        lagged_correlations.loc[lag, 'TextBlob'] = merged_data['textblob_sentiment'].corr(merged_data['Daily_Return'].shift(-lag))\n",
    "\n",
    "print(\"\\nLagged Correlations:\")\n",
    "display(lagged_correlations)\n",
    "\n",
    "# Visualize lagged correlations\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(lagged_correlations.index, lagged_correlations['VADER'], marker='o', label='VADER')\n",
    "plt.plot(lagged_correlations.index, lagged_correlations['TextBlob'], marker='o', label='TextBlob')\n",
    "plt.title('Lagged Correlations between Sentiment and Returns')\n",
    "plt.xlabel('Lag (days)')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Significance Testing\n",
    "\n",
    "We'll test the statistical significance of our correlations using:\n",
    "1. Pearson correlation test\n",
    "2. P-value analysis\n",
    "3. Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(\"Statistical Significance Tests:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# VADER sentiment\n",
    "vader_t_stat, vader_p_value = stats.pearsonr(merged_data['vader_compound'], merged_data['Daily_Return'])\n",
    "print(f\"VADER Sentiment:\")\n",
    "print(f\"t-statistic: {vader_t_stat:.3f}\")\n",
    "print(f\"p-value: {vader_p_value:.3f}\")\n",
    "print(f\"Significant at 5% level: {vader_p_value < 0.05}\")\n",
    "\n",
    "# TextBlob sentiment\n",
    "textblob_t_stat, textblob_p_value = stats.pearsonr(merged_data['textblob_sentiment'], merged_data['Daily_Return'])\n",
    "print(f\"\\nTextBlob Sentiment:\")\n",
    "print(f\"t-statistic: {textblob_t_stat:.3f}\")\n",
    "print(f\"p-value: {textblob_p_value:.3f}\")\n",
    "print(f\"Significant at 5% level: {textblob_p_value < 0.05}\")\n",
    "\n",
    "# Calculate confidence intervals\n",
    "def correlation_confidence_interval(r, n, alpha=0.05):\n",
    "    z = np.arctanh(r)\n",
    "    se = 1/np.sqrt(n-3)\n",
    "    z_score = stats.norm.ppf(1-alpha/2)\n",
    "    ci_lower = np.tanh(z - z_score*se)\n",
    "    ci_upper = np.tanh(z + z_score*se)\n",
    "    return ci_lower, ci_upper\n",
    "\n",
    "print(\"\\nConfidence Intervals (95%):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# VADER confidence interval\n",
    "vader_ci_lower, vader_ci_upper = correlation_confidence_interval(correlation_vader, len(merged_data))\n",
    "print(f\"VADER Sentiment: [{vader_ci_lower:.3f}, {vader_ci_upper:.3f}]\")\n",
    "\n",
    "# TextBlob confidence interval\n",
    "textblob_ci_lower, textblob_ci_upper = correlation_confidence_interval(correlation_textblob, len(merged_data))\n",
    "print(f\"TextBlob Sentiment: [{textblob_ci_lower:.3f}, {textblob_ci_upper:.3f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
